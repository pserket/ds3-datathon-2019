{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Local - Negative Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Problem Statement\n",
    "\n",
    "   We wanted to tackle what the general problems that businesses should strive to solve in order to prevent negative reviews.\n",
    "   \n",
    "### 2) Initial data analysis and findings\n",
    "   \n",
    "   We used a sample of ~500,000 reviews. Our initial data analysis looked into problems regarding the different languages in the review data and how tf-idf can be used to create accurate models. We also experimented with what size of n-gram would produce the most accurate model. We thought using larger sized n-grams as well as stop words would increase the accuracy of our model, however it turned out it did not. 1-3 words were the best way to split a review text and including the stop words also increased the accuracy. It is hard to see what effect the foreign languages had on our analysis because we were forced to leave many in the text, but the model was still able to perform reasonably well. We also tried other models such as multinomial naive bayes, and decision tree classifiers, but linear SVC performed the best. \n",
    "   \n",
    "### 3) Hypothesis testing and results\n",
    "    \n",
    "   Hypothesis: Reviews will have words that reflect the rating.\n",
    "\n",
    "   To test this, we first located the text reviews that were 3-stars or lower and analyzed if the reviews were reflective of the rating. We created a classifier based on a linear SVC model and n-gram features to predict whether a review would be negative or not which could achieve around 88% accuracy on test data. This led us to conclude that the reviews did contain information that were relevant to the negative rating. \n",
    "   \n",
    "### 4) Modelling / Summarizing insights\n",
    "    \n",
    "   With this knowledge, we took the negative reviews and created text summaries of length 4 to 5 words based on TF-IDF for each review. We then took these summaries to create a word cloud of all negative summaries. The most relevant words were \"food\", \"minute\", and \"service.\" From this, we can see that most issues stem from these general themes of food, time, and service.\n",
    "\n",
    "Members: Derrick Liu, Pete Sheurpukdi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"wordcloud.png\" style=\"width : 75%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUNQVEY73uZR"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_C3RvcBU45z_",
    "outputId": "7590bf4f-0d47-4f90-d34b-b4a99d285660"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-q1MUfl34MQa"
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('sample.reviews.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anWkuXi5_edO"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_classifier_binary(X, y):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    classifier = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(ngram_range=(1,3))), #including stop words because it yields higher accuracy\n",
    "        ('lin', LinearSVC())\n",
    "    ])\n",
    "\n",
    "    classifier.fit(X, y)\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0xX1omPUD0yq",
    "outputId": "d8231ee6-dee0-4d80-80a4-d23485101277"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86825"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df.dropna(subset=['reviewText', 'rating']).sample(100000)\n",
    "df['rating'] = df['rating'].apply(lambda x: 1 if x in [4,5] else 0)\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(lambda x: str.lower(x).strip().translate(str.maketrans('', '', string.punctuation)))\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['reviewText'], df['rating'], test_size=0.2)\n",
    "pl = create_classifier_binary(X_train, y_train)\n",
    "pl\n",
    "\n",
    "pl.score(X_test, y_test) #validate, see if accuracy is reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nymFWvj1JG7_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "TCnL0lJrF2e9",
    "outputId": "a54317a5-9669-44db-c97d-b2538508eae5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241338    0\n",
       "326769    0\n",
       "287719    1\n",
       "441866    1\n",
       "268857    1\n",
       "Name: predicted sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['predicted sentiment'] = pl.predict(df['reviewText'])\n",
    "df['predicted sentiment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69xFrZSVD3aC"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# get only the negative reviews in the dataframe\n",
    "sentiment = df\n",
    "\n",
    "d = sentiment.dropna(subset=['reviewText', 'rating'])\n",
    "# d['rating'] = d['rating'].apply(lambda x: 1 if x in [4,5] else 0)\n",
    "# d['reviewText'] = d['reviewText'].apply(lambda x: str.lower(x).strip().translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(4,5),stop_words='english')\n",
    "\n",
    "X = vectorizer.fit_transform(d['reviewText'])\n",
    "\n",
    "m = {v: k for (k, v) in vectorizer.vocabulary_.items()}\n",
    "\n",
    "ngram_summary = [m[t] for t in np.array(np.argmax(X, axis=1)).flatten()]\n",
    "\n",
    "d['ngram summary'] = ngram_summary\n",
    "\n",
    "d = d.reset_index()\n",
    "\n",
    "for i in range(len(d)):\n",
    "    if len(d.loc[i, 'reviewText'].split()) < 4:\n",
    "        d.loc[i, 'ngram summary'] = d.loc[i, 'reviewText']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below gives the negative reviews along with the generated n-gram tf-idf summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4145
    },
    "colab_type": "code",
    "id": "bCZS_tibB21J",
    "outputId": "d834f45b-9b8f-44d2-9a4d-f355bed603cf"
   },
   "outputs": [],
   "source": [
    "d[['rating', 'reviewText', 'predicted sentiment', 'ngram summary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhg0jEa-G4IA"
   },
   "source": [
    "We changed machines, and the second didn't have wordcloud installed so we just uploaded the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "YARyJBkbLeft",
    "outputId": "7982f705-91fc-480e-fa68-ef6c7dc98f90"
   },
   "outputs": [],
   "source": [
    "\n",
    "# from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "# import langdetect\n",
    "# df = d.copy()\n",
    "\n",
    "# df = df.dropna(subset=['reviewText', 'rating'])\n",
    "\n",
    "# df = df.loc[df['predicted sentiment'].astype(int) == 0]#['reviewText']\n",
    "\n",
    "# text = \" \".join(review for review in df['ngram summary'])\n",
    "\n",
    "# wordcloud = WordCloud().generate(text)\n",
    "\n",
    "# # Display the generated image:\n",
    "# plt.imshow(wordcloud, interpolation='bilinear')\n",
    "# plt.title('Word Cloud of Sampled Reviews Classified as Negative')\n",
    "# plt.show()\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTlHfeISgdV5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIh2QrsygiMY"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWYhC0TBwt-h"
   },
   "outputs": [],
   "source": [
    "#Language filtering TAKES TOO LONG TO RUN, SO WE WONT DO IT\n",
    "\n",
    "# from polyglot.detect import Detector\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# df = df.dropna(subset=['reviewText', 'rating'])\n",
    "\n",
    "# df['reviewText'] = df['reviewText'].apply(lambda x: str.lower(x).translate(str.maketrans('', '', string.punctuation)).strip())\n",
    "\n",
    "# df['reviewText'] = df['reviewText'].apply(lambda x: bytes(x, 'utf-8').decode('utf-8','ignore'))\n",
    "# df = df.loc[df['reviewText'] != ''].reset_index()\n",
    "\n",
    "\n",
    "# df['lang'] = df['reviewText'].apply(lambda x: Detector(x, quiet=True).languages[0].code)\n",
    "\n",
    "# #df1.loc[df1['Language'] == 'en']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHfkV-WzhDCm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxd0DO-xzHcL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WTL1Wlko1uBI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
